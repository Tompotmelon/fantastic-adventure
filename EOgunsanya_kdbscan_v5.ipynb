{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python312\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Algorithmic structure based on the K-DBSCAN: Kernel-Density-Based Spatial Clustering of Applications with Noise algorithm\n",
    "[@author: Eduardo Pla-Sacristan (Created Tue Mar 6 14:54:00 2018)]\n",
    "\n",
    "Theory from the following paper:\n",
    "\"K-DBSCAN: Identifying Spatial Clusters With Differing Density Levels\"\n",
    "[@authors: Madhuri Debnath, Praveen Kumar Tripathi, Ramez Elmasri]\n",
    "\n",
    "Written by Elizabeth Ogunsanya for analysis carried out in Advanced Spatial Analytics at Columbia GSAPP. \n",
    "This methodology was not used in the final report, Organized Displacement: \n",
    "A Policing Legacy (A study of the sustained impacts of Oakland’s gang injunctions on Black youth). \n",
    "The analysis was conducted in collaboration with Ki-Sang Yi and Tim Yoshimura Small, current MS in Urban Planning candidates\n",
    "at Columbia University Graduate School of Architecture, Planning and Preservation.\n",
    "\n",
    "Data held in the following Github Repository: \n",
    "https://github.com/Tompotmelon/fantastic-adventure\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ==================================================== IMPORTS ================================================ #\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from matplotlib import cm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.spatial import cKDTree\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================= LOADING IN DATA I =============================================== #\n",
    "\n",
    "def load_data(path, lat_col='lat', lon_col='lon', crs='epsg:4326', geom_col=None):\n",
    "    data = pd.read_csv(path)\n",
    "    if geom_col:\n",
    "        data[geom_col] = data[geom_col].apply(wkt.loads)\n",
    "        gdf = gpd.GeoDataFrame(data, geometry=geom_col)\n",
    "    else:\n",
    "        gdf = gpd.GeoDataFrame(data, geometry=gpd.points_from_xy(data[lon_col], data[lat_col]))\n",
    "    gdf.set_crs(crs, inplace=True)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================= LOADING IN DATA II =============================================== #\n",
    "\n",
    "base_path = 'Data/'\n",
    "\n",
    "# CITY-WIDE\n",
    "force2020_gdf = load_data(base_path + 'use_of_force_cleaned_2020_latlon.csv')\n",
    "force2015_gdf = load_data(base_path + 'use_of_force_cleaned_2015_latlon.csv')\n",
    "stops2015_gdf = load_data(base_path + 'stops_cleaned_2015_latlon.csv')\n",
    "stops2020_gdf = load_data(base_path + 'stops_cleaned_2020_latlon.csv')\n",
    "arrests2015_gdf = load_data(base_path + 'oakland_arrests_2015.csv', geom_col='Location')\n",
    "arrests2020_gdf = load_data(base_path + 'oakland_arrests_2020.csv', geom_col='Location')\n",
    "police_activity_2015 = gpd.read_file(base_path + 'police_activity_2015.shp')\n",
    "police_activity_2020 = gpd.read_file(base_path + 'police_activity_2020.shp')\n",
    "study_pop_block_2015 = gpd.read_file(base_path + 'StudyPop_perBlock_2015.shp')\n",
    "study_pop_block_2020 = gpd.read_file(base_path + 'StudyPop_perBlock_2020.shp')\n",
    "\n",
    "# WITHIN GIZs\n",
    "force2020_northoak_gdf = gpd.read_file(base_path + 'oakland_use_of_force_2020_northoak_GIZ.shp')\n",
    "force2015_northoak_gdf = gpd.read_file(base_path + 'oakland_use_of_force_2015_northoak_GIZ.shp')\n",
    "force2020_fruitvale_gdf = gpd.read_file(base_path + 'oakland_use_of_force_2020_fruitvale_GIZ.shp')\n",
    "force2015_fruitvale_gdf = gpd.read_file(base_path + 'oakland_use_of_force_2015_fruitvale_GIZ.shp')\n",
    "stops2020_northoak_gdf = gpd.read_file(base_path + 'oakland_stops_2020_northoak_GIZ.shp')\n",
    "stops2015_northoak_gdf = gpd.read_file(base_path + 'oakland_stops_2015_northoak_GIZ.shp')\n",
    "stops2020_fruitvale_gdf = gpd.read_file(base_path + 'oakland_stops_2020_fruitvale_GIZ.shp')\n",
    "stops2015_fruitvale_gdf = gpd.read_file(base_path + 'oakland_stops_2015_fruitvale_GIZ.shp')\n",
    "arrests2020_northoak_gdf = gpd.read_file(base_path + 'oakland_arrests_2020_northoak_GIZ.shp')\n",
    "arrests2015_northoak_gdf = gpd.read_file(base_path + 'oakland_arrests_2015_northoak_GIZ.shp')\n",
    "arrests2020_fruitvale_gdf = gpd.read_file(base_path + 'oakland_arrests_2020_fruitvale_GIZ.shp')\n",
    "arrests2015_fruitvale_gdf = gpd.read_file(base_path + 'oakland_arrests_2015_fruitvale_GIZ.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and titles mapping\n",
    "gdfs = {\n",
    "    'force2020_gdf': force2020_gdf,\n",
    "    'force2015_gdf': force2015_gdf,\n",
    "    'stops2020_gdf': stops2020_gdf,\n",
    "    'stops2015_gdf': stops2015_gdf,\n",
    "    'arrests2015_gdf': arrests2015_gdf,\n",
    "    'arrests2020_gdf': arrests2020_gdf,\n",
    "    'police_activity_2015': police_activity_2015,\n",
    "    'police_activity_2020': police_activity_2020,\n",
    "    'force2020_northoak_gdf': force2020_northoak_gdf,\n",
    "    'force2015_northoak_gdf': force2015_northoak_gdf,\n",
    "    'force2020_fruitvale_gdf': force2020_fruitvale_gdf,\n",
    "    'force2015_fruitvale_gdf': force2015_fruitvale_gdf,\n",
    "    'stops2020_northoak_gdf': stops2020_northoak_gdf,\n",
    "    'stops2015_northoak_gdf': stops2015_northoak_gdf,\n",
    "    'stops2020_fruitvale_gdf': stops2020_fruitvale_gdf,\n",
    "    'stops2015_fruitvale_gdf': stops2015_fruitvale_gdf,\n",
    "    'arrests2020_northoak_gdf': arrests2020_northoak_gdf,\n",
    "    'arrests2015_northoak_gdf': arrests2015_northoak_gdf,\n",
    "    'arrests2020_fruitvale_gdf': arrests2020_fruitvale_gdf,\n",
    "    'arrests2015_fruitvale_gdf': arrests2015_fruitvale_gdf,\n",
    "    'study_pop_block_2015': study_pop_block_2015,\n",
    "    'study_pop_block_2020': study_pop_block_2020\n",
    "}\n",
    "\n",
    "gdf_csv = {\n",
    "    'force2020_gdf': force2020_gdf,\n",
    "    'force2015_gdf': force2015_gdf,\n",
    "    'stops2020_gdf': stops2020_gdf,\n",
    "    'stops2015_gdf': stops2015_gdf,\n",
    "    'arrests2015_gdf': arrests2015_gdf,\n",
    "    'arrests2020_gdf': arrests2020_gdf,\n",
    "}\n",
    "\n",
    "# k = 4\n",
    "gdf_csv_1 = {\n",
    "    'force2020_gdf': force2020_gdf,\n",
    "    'force2015_gdf': force2015_gdf,\n",
    "    'stops2020_gdf': stops2020_gdf,\n",
    "}\n",
    "\n",
    "\n",
    "# k = 2\n",
    "gdf_csv_2 = {\n",
    "    'stops2015_gdf': stops2015_gdf,\n",
    "    'arrests2015_gdf': arrests2015_gdf,\n",
    "    'arrests2020_gdf': arrests2020_gdf,\n",
    "}\n",
    "\n",
    "gdf_shp = {\n",
    "    'police_activity_2015': police_activity_2015,\n",
    "    'police_activity_2020': police_activity_2020,\n",
    "    'force2020_northoak_gdf': force2020_northoak_gdf,\n",
    "    'force2015_northoak_gdf': force2015_northoak_gdf,\n",
    "    'force2020_fruitvale_gdf': force2020_fruitvale_gdf,\n",
    "    'force2015_fruitvale_gdf': force2015_fruitvale_gdf,\n",
    "    'stops2020_northoak_gdf': stops2020_northoak_gdf,\n",
    "    'stops2015_northoak_gdf': stops2015_northoak_gdf,\n",
    "    'stops2020_fruitvale_gdf': stops2020_fruitvale_gdf,\n",
    "    'stops2015_fruitvale_gdf': stops2015_fruitvale_gdf,\n",
    "    'arrests2020_northoak_gdf': arrests2020_northoak_gdf,\n",
    "    'arrests2015_northoak_gdf': arrests2015_northoak_gdf,\n",
    "    'arrests2020_fruitvale_gdf': arrests2020_fruitvale_gdf,\n",
    "    'arrests2015_fruitvale_gdf': arrests2015_fruitvale_gdf,\n",
    "    # 'study_pop_block_2015': study_pop_block_2015,\n",
    "    # 'study_pop_block_2020': study_pop_block_2020\n",
    "}\n",
    "\n",
    "titles = {\n",
    "    'force2020_gdf': 'Use of Force 2020',\n",
    "    'force2015_gdf': 'Use of Force 2015',\n",
    "    'stops2020_gdf': 'Stops 2020',\n",
    "    'stops2015_gdf': 'Stops 2015',\n",
    "    'arrests2015_gdf': 'Arrests 2015',\n",
    "    'arrests2020_gdf': 'Arrests 2020',\n",
    "    'police_activity_2015': 'Aggregated Police Activity 2015',\n",
    "    'police_activity_2020': 'Aggregated Police Activity 2020',\n",
    "    'force2020_gdf': 'Use of Force 2020',\n",
    "    'force2015_gdf': 'Use of Force 2015',\n",
    "    'stops2020_gdf': 'Stops 2020',\n",
    "    'stops2015_gdf': 'Stops 2015',\n",
    "    'arrests2015_gdf': 'Arrests 2015',\n",
    "    'arrests2020_gdf': 'Arrests 2020',\n",
    "    'police_activity_2015': 'Aggregated Police Activity 2015',\n",
    "    'police_activity_2020': 'Aggregated Police Activity 2020',\n",
    "    'force2020_northoak_gdf': 'Use of Force in North Oakland 2020',\n",
    "    'force2015_northoak_gdf': 'Use of Force in North Oakland 2015',\n",
    "    'force2020_fruitvale_gdf': 'Use of Force in Fruitvale 2020',\n",
    "    'force2015_fruitvale_gdf': 'Use of Force in Fruitvale 2015',\n",
    "    'stops2020_northoak_gdf': 'Stops in North Oakland 2020',\n",
    "    'stops2015_northoak_gdf': 'Stops in North Oakland 2015',\n",
    "    'stops2015_fruitvale_gdf': 'Stops in Fruitvale 2015',\n",
    "    'stops2020_fruitvale_gdf': 'Stops in Fruitvale 2020',\n",
    "    'arrests2015_northoak_gdf': 'Arrests in North Oakland 2015',\n",
    "    'arrests2020_northoak_gdf': 'Arrests in North Oakland 2020',\n",
    "    'arrests2015_fruitvale_gdf': 'Arrests in Fruitvale 2015',\n",
    "    'arrests2020_fruitvale_gdf': 'Arrests in Fruitvale 2020',\n",
    "    'study_pop_block_2015': 'Study Population 2015',\n",
    "    'study_pop_block_2020': 'Study Population 2020'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  =========================================== SET CRS TO EPSG:2227 ================================= #\n",
    "\n",
    "for gdf_name, gdf in gdfs.items():\n",
    "    if gdf.crs is not None and gdf.crs.to_string() != 'epsg:2227':\n",
    "        gdf = gdf.to_crs('epsg:2227')  # Convert CRS if needed\n",
    "\n",
    "    # Handle non-point geometries by using centroids\n",
    "    if any(gdf.geom_type != 'Point'):\n",
    "        gdf['geometry'] = gdf.geometry.centroid\n",
    "\n",
    "    coords = np.array(list(zip(gdf.geometry.x, gdf.geometry.y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_save_dir = 'C:/Users/elleo/OneDrive/Documents/Columbia GSAPP/Spring 2024/Advanced Spatial Analysis/Plots/Trial_4/'\n",
    "os.makedirs(plot_save_dir, exist_ok=True)  # Creates the directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================== PRE-PROCESSING FOR K-MEANS ========================================= #\n",
    "\n",
    "# Calculate l-densities in order to select appropriate k for k-means clustering\n",
    "def calculate_ldensities(data, num_neighbors):\n",
    "    \"\"\"\n",
    "    Calculate l-densities for given coordinate data, ensuring no division by zero and handling NaNs.\n",
    "    \"\"\"\n",
    "    # Ensure data does not contain NaNs by using an imputer or dropping NaNs\n",
    "    if np.isnan(data).any():\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        data = imputer.fit_transform(data)\n",
    "\n",
    "    neigh = NearestNeighbors(n_neighbors=num_neighbors + 1)\n",
    "    neigh.fit(data)\n",
    "    distances, _ = neigh.kneighbors(data)\n",
    "    distances = distances[:, 1:]  # Exclude the point itself\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        l_densities = 1 / np.mean(distances, where=(distances != 0), axis=1)\n",
    "        l_densities[np.isinf(l_densities)] = 0  # Handle infinite values\n",
    "    return l_densities\n",
    "\n",
    "def plot_ldensities(l_densities, title, plot_save_dir):\n",
    "    \"\"\"\n",
    "    Plot the sorted l-density values and save the plot.\n",
    "    \"\"\"\n",
    "    sorted_l_densities = np.sort(l_densities)\n",
    "    plt.scatter(range(len(sorted_l_densities)), sorted_l_densities, s=5)\n",
    "    plt.xlabel('Points (sorted)')\n",
    "    plt.ylabel('l-density')\n",
    "    plt.title(f'Sorted l-densities: {title}')\n",
    "    plt.savefig(f'{plot_save_dir}{title.replace(\" \", \"_\")}_LDensities.png')\n",
    "    plt.show()\n",
    "\n",
    "def perform_kmeans(data, num_clusters):\n",
    "    \"\"\"\n",
    "    Perform K-means clustering on the given data and return the cluster labels.\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(data)\n",
    "    return kmeans.labels_\n",
    "\n",
    "def plot_kmeans(kmeans, title, plot_save_dir):\n",
    "    \"\"\"\n",
    "    Plot k-means clusters and save the plot\n",
    "    \"\"\"\n",
    "    plt.scatter(coords[:, 0], coords[:, 1], c= cluster_labels, cmap='viridis', s=8)\n",
    "    plt.xlabel('Easting (m)')\n",
    "    plt.ylabel('Northing (m)')\n",
    "    plt.title(f'K-Means Clusters: {title}')\n",
    "    plt.savefig(f'{plot_save_dir}{title.replace(\" \", \"_\")}_kmeans.png')\n",
    "    plt.savefig(f'{plot_save_dir}{title.replace(\" \", \"_\")}_kmeans.svg')\n",
    "    plt.show()\n",
    "\n",
    "def export_to_geojson(self, data, labels, filename):\n",
    "        \"\"\"\n",
    "        Export clustering results to a GeoJSON file.\n",
    "\n",
    "        Parameters:\n",
    "        data (numpy.ndarray): The dataset used for clustering.\n",
    "        labels (numpy.ndarray): Cluster labels for each point.\n",
    "        filename (str): File path where the GeoJSON will be saved.\n",
    "        \"\"\"\n",
    "        gdf = gpd.GeoDataFrame(columns=['geometry', 'cluster'])\n",
    "        gdf['geometry'] = [Point(xy) for xy in zip(data[:, 1], data[:, 0])]\n",
    "        gdf['cluster'] = labels\n",
    "        gdf.to_file(filename, driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  =================================== L-DENSITIES CSV FILES =============================== #\n",
    "\n",
    "# Calculate l-densities\n",
    "for gdf_name, gdf in gdf_csv.items():\n",
    "    if gdf.crs is not None and gdf.crs.to_string() != 'epsg:2227':\n",
    "        gdf = gdf.to_crs('epsg:2227')  # Convert CRS if needed\n",
    "\n",
    "    # Handle non-point geometries by using centroids\n",
    "    if any(gdf.geom_type != 'Point'):\n",
    "        gdf['geometry'] = gdf.geometry.centroid\n",
    "\n",
    "    coords = np.array(list(zip(gdf.geometry.x, gdf.geometry.y)))\n",
    "\n",
    "    # Calculate l-densities\n",
    "    l_densities = calculate_ldensities(coords, 5)\n",
    "    \n",
    "    # Plot l-densities\n",
    "    plot_ldensities(l_densities, gdf_name, plot_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  =================================== L-DENSITIES SHP FILES =============================== #\n",
    "\n",
    "# Calculate l-densities\n",
    "for gdf_name, gdf in gdf_shp.items():\n",
    "    if gdf.crs is not None and gdf.crs.to_string() != 'epsg:2227':\n",
    "        gdf = gdf.to_crs('epsg:2227')  # Convert CRS if needed\n",
    "\n",
    "    # Handle non-point geometries by using centroids\n",
    "    if any(gdf.geom_type != 'Point'):\n",
    "        gdf['geometry'] = gdf.geometry.centroid\n",
    "\n",
    "    coords = np.array(list(zip(gdf.geometry.x, gdf.geometry.y)))\n",
    "\n",
    "    # Calculate l-densities\n",
    "    l_densities = calculate_ldensities(coords, 5)\n",
    "    \n",
    "    # Plot l-densities\n",
    "    plot_ldensities(l_densities, gdf_name, plot_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ================================== K-MEANS CSV FILES =================================== #\n",
    "for gdf_name, gdf in gdf_csv_1.items():\n",
    "    title = titles[gdf_name]\n",
    "    coords = np.array(list(zip(gdf.geometry.x, gdf.geometry.y)))\n",
    "\n",
    "    # Ensure there are no NaNs in your coordinates\n",
    "    coords = np.nan_to_num(coords, nan=np.nanmean(coords))  # Replace NaNs with the mean of columns\n",
    "\n",
    "    num_clusters = 4  # Adjust based on your needs\n",
    "    cluster_labels = perform_kmeans(coords, num_clusters)\n",
    "    plot_kmeans(cluster_labels, title, plot_save_dir)\n",
    "\n",
    "for gdf_name, gdf in gdf_csv_2.items():\n",
    "    title = titles[gdf_name]\n",
    "    coords = np.array(list(zip(gdf.geometry.x, gdf.geometry.y)))\n",
    "\n",
    "    # Ensure there are no NaNs in your coordinates\n",
    "    coords = np.nan_to_num(coords, nan=np.nanmean(coords))  # Replace NaNs with the mean of columns\n",
    "\n",
    "    num_clusters = 2  # Adjust based on your needs\n",
    "    cluster_labels = perform_kmeans(coords, num_clusters)\n",
    "    plot_kmeans(cluster_labels, title, plot_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gdf_3 = {\n",
    "    'police_activity_2015': police_activity_2015,\n",
    "    'police_activity_2020': police_activity_2020,\n",
    "    'force2020_northoak_gdf': force2020_northoak_gdf,\n",
    "    'arrests2020_northoak_gdf': arrests2020_northoak_gdf,\n",
    "    'arrests2020_gdf': arrests2020_gdf,\n",
    "    'stops2015_gdf': stops2015_gdf,\n",
    "    # 'study_pop_block_2015': study_pop_block_2015,\n",
    "    # 'study_pop_block_2020': study_pop_block_2020\n",
    "}\n",
    "\n",
    "# l > 15\n",
    "gdf_3a = {\n",
    "        'arrests2015_northoak_gdf': arrests2015_northoak_gdf,\n",
    "        'arrests2015_fruitvale_gdf': arrests2015_fruitvale_gdf,\n",
    "\n",
    "}\n",
    "\n",
    "gdf_4 = {\n",
    "    'force2015_fruitvale_gdf': force2015_fruitvale_gdf,\n",
    "    'stops2020_northoak_gdf': stops2020_northoak_gdf,\n",
    "}\n",
    "\n",
    "gdf_5 = {\n",
    "    'stops2015_fruitvale_gdf': stops2015_fruitvale_gdf,\n",
    "    'arrests2015_fruitvale_gdf': arrests2015_fruitvale_gdf,\n",
    "    'stops2020_fruitvale_gdf': stops2020_fruitvale_gdf,\n",
    "    'force2020_gdf': force2020_gdf,\n",
    "    'stops2020_gdf': stops2020_gdf,\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "gdf_6 = {\n",
    "    'force2015_northoak_gdf': force2015_northoak_gdf,\n",
    "    'arrests2015_northoak_gdf': arrests2015_northoak_gdf,\n",
    "    'arrests2020_fruitvale_gdf': arrests2020_fruitvale_gdf,\n",
    "    'arrests2015_gdf': arrests2015_gdf,\n",
    "    'stops2015_northoak_gdf': stops2015_northoak_gdf,\n",
    "}\n",
    "\n",
    "gdf_7 = {\n",
    "    'force2020_fruitvale_gdf': force2020_fruitvale_gdf,\n",
    "    'force2015_gdf': force2015_gdf,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================== K-MEANS SHP FILES ================================== #\n",
    "for gdf_name, gdf in gdf_3.items():\n",
    "    title = titles[gdf_name]\n",
    "    coords = np.array(list(zip(gdf.geometry.x, gdf.geometry.y)))\n",
    "\n",
    "    # Ensure there are no NaNs in your coordinates\n",
    "    coords = np.nan_to_num(coords, nan=np.nanmean(coords))  # Replace NaNs with the mean of columns\n",
    "\n",
    "    num_clusters =   # Adjust based on your needs\n",
    "    cluster_labels = perform_kmeans(coords, num_clusters)\n",
    "    plot_kmeans(cluster_labels, title, plot_save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gdf_name, gdf in gdf_3.items():\n",
    "    # Convert all geometries to points (e.g., using centroid if they are polygons)\n",
    "    gdf['geometry'] = gdf.geometry.centroid\n",
    "    \n",
    "    title = titles[gdf_name]\n",
    "    coords = np.array(list(zip(gdf.geometry.x, gdf.geometry.y)))\n",
    "\n",
    "    # Ensure there are no NaNs in your coordinates\n",
    "    coords = np.nan_to_num(coords, nan=np.nanmean(coords))  # Replace NaNs with the mean of columns\n",
    "\n",
    "    num_clusters = 3  # Adjust based on your needs\n",
    "    cluster_labels = perform_kmeans(coords, num_clusters)\n",
    "    plot_kmeans(cluster_labels, title, plot_save_dir)\n",
    "\n",
    "for gdf_name, gdf in gdf_4.items():\n",
    "    # Convert all geometries to points (e.g., using centroid if they are polygons)\n",
    "    gdf['geometry'] = gdf.geometry.centroid\n",
    "\n",
    "    title = titles[gdf_name]\n",
    "    coords = np.array(list(zip(gdf.geometry.x, gdf.geometry.y)))\n",
    "\n",
    "    # Ensure there are no NaNs in your coordinates\n",
    "    coords = np.nan_to_num(coords, nan=np.nanmean(coords))  # Replace NaNs with the mean of columns\n",
    "\n",
    "    num_clusters = 4  # Adjust based on your needs\n",
    "    cluster_labels = perform_kmeans(coords, num_clusters)\n",
    "    plot_kmeans(cluster_labels, title, plot_save_dir)\n",
    "\n",
    "for gdf_name, gdf in gdf_5.items():\n",
    "    # Convert all geometries to points (e.g., using centroid if they are polygons)\n",
    "    gdf['geometry'] = gdf.geometry.centroid\n",
    "\n",
    "    title = titles[gdf_name]\n",
    "    coords = np.array(list(zip(gdf.geometry.x, gdf.geometry.y)))\n",
    "\n",
    "    # Ensure there are no NaNs in your coordinates\n",
    "    coords = np.nan_to_num(coords, nan=np.nanmean(coords))  # Replace NaNs with the mean of columns\n",
    "\n",
    "    num_clusters = 5  # Adjust based on your needs\n",
    "    cluster_labels = perform_kmeans(coords, num_clusters)\n",
    "    plot_kmeans(cluster_labels, title, plot_save_dir)\n",
    "\n",
    "for gdf_name, gdf in gdf_6.items():\n",
    "    # Convert all geometries to points (e.g., using centroid if they are polygons)\n",
    "    gdf['geometry'] = gdf.geometry.centroid\n",
    "\n",
    "    title = titles[gdf_name]\n",
    "    coords = np.array(list(zip(gdf.geometry.x, gdf.geometry.y)))\n",
    "\n",
    "    # Ensure there are no NaNs in your coordinates\n",
    "    coords = np.nan_to_num(coords, nan=np.nanmean(coords))  # Replace NaNs with the mean of columns\n",
    "\n",
    "    num_clusters = 6  # Adjust based on your needs\n",
    "    cluster_labels = perform_kmeans(coords, num_clusters)\n",
    "    plot_kmeans(cluster_labels, title, plot_save_dir)\n",
    "\n",
    "for gdf_name, gdf in gdf_7.items():\n",
    "    # Convert all geometries to points (e.g., using centroid if they are polygons)\n",
    "    gdf['geometry'] = gdf.geometry.centroid\n",
    "    \n",
    "    coords = np.array(list(zip(gdf.geometry.x, gdf.geometry.y)))\n",
    "    title = titles[gdf_name]\n",
    "    coords = np.array(list(zip(gdf.geometry.x, gdf.geometry.y)))\n",
    "\n",
    "    # Ensure there are no NaNs in your coordinates\n",
    "    coords = np.nan_to_num(coords, nan=np.nanmean(coords))  # Replace NaNs with the mean of columns\n",
    "\n",
    "    num_clusters = 7  # Adjust based on your needs\n",
    "    cluster_labels = perform_kmeans(coords, num_clusters)\n",
    "    plot_kmeans(cluster_labels, title, plot_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class KDBSCAN:\n",
    "    def __init__(self, radius_func, num_neighbors=20):\n",
    "        self.radius_func = radius_func\n",
    "        self.num_neighbors = num_neighbors\n",
    "\n",
    "    def radius_func(self, coords, point_index, l=20):\n",
    "        tree = cKDTree(coords)\n",
    "        distances, indexes = tree.query(coords[point_index], k=l+1)\n",
    "        geodesic_distances = [geodesic((coords[point_index][1], coords[point_index][0]),\n",
    "                                        (coords[idx][1], coords[idx][0])).meters for idx in indexes[1:]]\n",
    "        geodesic_distances.sort()\n",
    "        epsilon_i = geodesic_distances[-1]\n",
    "        return epsilon_i\n",
    "\n",
    "    def fit(self, gdf, num_clusters):\n",
    "        if gdf.crs.to_string() != 'epsg:2227':\n",
    "            gdf = gdf.to_crs('epsg:2227')\n",
    "        gdf['geometry'] = gdf.geometry.centroid\n",
    "        coords = np.array(list(zip(gdf.geometry.x, gdf.geometry.y)))\n",
    "        kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(coords)\n",
    "        self.density_levels = kmeans.labels_\n",
    "\n",
    "        gdf_4326 = gdf.to_crs('epsg:4326')\n",
    "        coords_4326 = np.array(list(zip(gdf_4326.geometry.x, gdf_4326.geometry.y)))\n",
    "        self.CL = np.zeros(len(coords), dtype=int)\n",
    "        visited = set()\n",
    "        cluster_id = 1\n",
    "\n",
    "        for i, point in enumerate(coords):\n",
    "            if i not in visited:\n",
    "                visited.add(i)\n",
    "                εi = self.radius_func(coords_4326, i, l=5)\n",
    "                NeighborPts = self.regionQuery(coords, i, εi)\n",
    "                if len(NeighborPts) > self.num_neighbors:\n",
    "                    self.expandCluster(coords, coords_4326, i, NeighborPts, cluster_id, visited)\n",
    "                    cluster_id += 1\n",
    "\n",
    "        gdf['cluster'] = self.CL\n",
    "        return gdf\n",
    "\n",
    "    def regionQuery(self, coords, idx, εi):\n",
    "        distances = np.linalg.norm(coords - coords[idx], axis=1)\n",
    "        return np.where((distances <= εi) & (self.density_levels == self.density_levels[idx]))[0]\n",
    "\n",
    "    def expandCluster(self, coords, coords_4326, idx, NeighborPts, cluster_id, visited):\n",
    "        self.CL[idx] = cluster_id\n",
    "        points_to_evaluate = list(NeighborPts)\n",
    "        i = 0\n",
    "\n",
    "        while i < len(points_to_evaluate):\n",
    "            point = points_to_evaluate[i]\n",
    "            if point not in visited:\n",
    "                visited.add(point)\n",
    "                self.CL[point] = cluster_id\n",
    "                εi = self.radius_func(coords_4326, point, l=5)\n",
    "                new_points = self.regionQuery(coords, point, εi)\n",
    "\n",
    "                if len(new_points) >= self.num_neighbors:\n",
    "                    points_to_evaluate.extend([np for np in new_points if np not in visited and np not in points_to_evaluate])\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    def calculate_ldensities(self, data, num_neighbors):\n",
    "        neigh = NearestNeighbors(n_neighbors=num_neighbors + 1)\n",
    "        neigh.fit(data)\n",
    "        distances, _ = neigh.kneighbors(data)\n",
    "        distances = distances[:, 1:]  # Exclude the point itself\n",
    "        l_densities = np.zeros(data.shape[0])\n",
    "        for i, dist in enumerate(distances):\n",
    "            if np.any(dist > 0):\n",
    "                l_densities[i] = 1 / np.mean(dist[dist > 0])\n",
    "            else:\n",
    "                l_densities[i] = 0\n",
    "        return l_densities\n",
    "\n",
    "    def save_geojson(self, gdf, filename):\n",
    "        gdf.to_file(filename, driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN K-DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 3\n",
    "for gdf_name, gdf in gdf_3.items():\n",
    "    title = titles[gdf_name]\n",
    "\n",
    "    num_clusters = 3  # k\n",
    "    kdb = KDBSCAN(radius_func, num_neighbors=5)\n",
    "    clustered_gdf = kdb.fit(gdf)\n",
    "    # clustered_gdf.to_crs('epsg:4326', inplace=True)  # Convert back to WGS 84 for GeoJSON compatibility\n",
    "    kdb.save_geojson(clustered_gdf, f'C:/Users/elleo/OneDrive/Documents/Columbia GSAPP/Spring 2024/Advanced Spatial Analysis/Plots/Trial_4/{title.replace(\" \", \"_\")}_clustered_KDBSCAN_data.geojson')\n",
    "\n",
    "    # Plot with dynamic title\n",
    "    plot_kdbscan(clustered_gdf, gdf_name, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 4\n",
    "for gdf_name, gdf in gdf_4.items():\n",
    "    title = titles[gdf_name]\n",
    "\n",
    "    num_clusters = 4  # k\n",
    "    kdb = KDBSCAN(radius_func, num_neighbors=5)\n",
    "    # Call fit with the GeoDataFrame and num_clusters\n",
    "    clustered_gdf = kdb.fit(gdf, num_clusters)\n",
    "    # clustered_gdf.to_crs('epsg:4326', inplace=True)  # Convert back to WGS 84 for GeoJSON compatibility\n",
    "    kdb.save_geojson(clustered_gdf, f'C:/Users/elleo/OneDrive/Documents/Columbia GSAPP/Spring 2024/Advanced Spatial Analysis/Plots/Trial_4/{title.replace(\" \", \"_\")}_clustered_KDBSCAN_data.geojson')\n",
    "\n",
    "    # Plot with dynamic title\n",
    "    plot_kdbscan(clustered_gdf, gdf_name, titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 5\n",
    "for gdf_name, gdf in gdf_5.items():\n",
    "    title = titles[gdf_name]\n",
    "\n",
    "    num_clusters = 5  # k\n",
    "    kdb = KDBSCAN(radius_func, num_neighbors=5)\n",
    "    clustered_gdf = kdb.fit(gdf)\n",
    "    # clustered_gdf.to_crs('epsg:4326', inplace=True)  # Convert back to WGS 84 for GeoJSON compatibility\n",
    "    kdb.save_geojson(clustered_gdf, f'C:/Users/elleo/OneDrive/Documents/Columbia GSAPP/Spring 2024/Advanced Spatial Analysis/Plots/Trial_4/{title.replace(\" \", \"_\")}_clustered_KDBSCAN_data.geojson')\n",
    "\n",
    "    # Plot with dynamic title\n",
    "    plot_kdbscan(clustered_gdf, gdf_name, titles)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
